version: '3.7'


services:
  hive-metastore:
    image: hub.teko.vn/dataops/hive:3.1.3
    # HOTFIX: Illegal character in hostname at index 13: thrift://hive_hive-metastore_1.bookshelf:9083
    # Caused at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.resolveUris(HiveMetaStoreClient.java:267)
    container_name: hive-metastore
    entrypoint: [ "/usr/local/scripts/metastore-entrypoint.sh" ]
    depends_on:
      - postgres
    environment:
      HADOOP_OPTIONAL_TOOLS: hadoop-aws
    networks:
      default:
        ipv4_address: 10.5.0.9
    ports:
      - 9083:9083
    volumes:
      - ./hive/scripts/:/usr/local/scripts/
      - ./hive/configs/hive/:/opt/hive/conf/
      - ./hive/configs/hadoop/:/opt/hadoop/etc/hadoop/
      - /tmp/:/tmp/

  ##### Hive Beeline #####
  # https://iceberg.apache.org/docs/latest/hive/
  # Help:
  # $ beeline -u jdbc:hive2://localhost:10000
  # beeline> ADD JAR /path/to/iceberg-hive-runtime.jar;
  # beeline> SHOW DATABASES;
  hive-server2:
    image: hub.teko.vn/dataops/hive:3.1.3
    entrypoint: [ "/usr/local/scripts/hiveserver2-entrypoint.sh" ]
    depends_on:
      - hive-metastore
    environment:
      HADOOP_OPTIONAL_TOOLS: hadoop-aws
    networks:
      default:
        ipv4_address: 10.5.0.10
    # ports:
    #   - 10000:10000
    #   - 10002:10002 # WebUI
    volumes:
      - ./hive/scripts/:/usr/local/scripts/
      - ./hive/configs/hive/:/opt/hive/conf/
      - ./hive/configs/hadoop/:/opt/hadoop/etc/hadoop/

  minio:
    image: minio/minio
    command: [ server, --address=:9000, --console-address=:9001, /data ]
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: SuperSecr3t
    networks:
      default:
        ipv4_address: 10.5.0.11
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - minio_data:/data

  jupyter:
    image: hub.teko.vn/dataops/jupyter/pyspark-notebook:3.2.0
    command: [ start-notebook.sh, --NotebookApp.token='' ]
    environment:
      GRANT_SUDO: "yes"
      JUPYTER_ENABLE_LAB: "yes"
      HADOOP_OPTIONAL_TOOLS: hadoop-aws
      AWS_REGION: aws-global
    user: root
    ports:
      - 8888:8888
      - 4040:4040 # spark app
    volumes:
      - ./spark/:/opt/spark/conf/

volumes:
  minio_data:

networks:
  default:
    name: alluvial
    external: true
